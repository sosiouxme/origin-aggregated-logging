# Logging Deployer

The deployer pod can enable deploying the full stack of the aggregated
logging solution with just a few prerequisites:

1. A "logging-deployer" Secret
2. A "logging-deployer" ServiceAccount with the secret and create privileges
3. Optionally, a key and certificate for the Kibana server to be deployed.
4. Sufficient PersistentVolumes defined for ElasticSearch cluster storage.

The deployer generates all the necessary certs/keys/etc for cluster
communication and defines secrets and templates for all of the necessary
API objects to implement aggregated logging. There are a number of
manual steps you must run with cluster-admin privileges in order to
create an OAuth client and modify the privileged SCC so fluentd can run
as a privileged pod on every node.

## Choose a Project

You will likely want to put all logging-related entities in their own project.
For this document we will assume the `logging` project.

    oc new-project logging

You can use the default project if you want. When deploying fluentd as a static
pod, this was necessary as that was the namespace given to mirror pods. This
deployment has no need to run in the default project.

## Create the Secret

All contents of the secret are optional, but the secret itself must always be
created in order to deploy. For an empty secret:

    oc secrets new logging-deployer nothing=/dev/null

The following files may be supplied in the deployer secret:

* `kibana.crt` - A browser-facing certificate for the Kibana server.
* `kibana.key` - A key to be used with the Kibana certificate.
* `server-tls.json` - JSON TLS options to override the Kibana server defaults; refer to
  [NodeJS docs](https://nodejs.org/api/tls.html#tls_tls_connect_options_callback) for
  available options and the [default options](conf/server-tls.json) for an example.
* `ca.crt` - A certificate for a CA that will be used to sign all certificates
  generated by the deployer.
* `ca.key` - A matching CA key.

An invocation supplying a properly signed Kibana cert might be:

    oc secrets new logging-deployer \
       kibana.crt=/path/to/cert kibana.key=/path/to/key

## Create the ServiceAccount

The deployer must run under a special service account defined as follows:

    oc create -f - <<API
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: logging-deployer
    secrets:
    - name: logging-deployer
    API

    openshift admin policy add-role-to-user edit \
              system:serviceaccount:logging:logging-deployer

Note you should replace ":logging:" with the project name.

## Run the Deployer

You will need to specify the hostname at which Kibana should be exposed to client
browsers, and also the master URL where client browsers will be directed for
authenticating to OpenShift. With example parameters:

    oc process logging-deployer-template \
               -v KIBANA_HOSTNAME=kibana.example.com,PUBLIC_MASTER_URL=https://localhost:8443 \
               | oc create -f -

Check the logs of the resulting pod for further instructions on deploying the result.

## Cleanup and removal

After deployment, the deployer account and secret can be removed.

    oc delete sa/logging-deployer secret/logging-deployer

When the deployer runs, it deletes any existing logging objects
to make way for defining new ones. You can also do this manually:

    oc delete template --selector logging-infra=support
    oc delete all --selector logging-infra=kibana
    oc delete all --selector logging-infra=fluentd
    oc delete all,pvc --selector logging-infra=elasticsearch
    oc delete all,sa,oauthclient --selector logging-infra=support
    oc delete secret logging-fluentd logging-elasticsearch logging-es-proxy logging-kibana logging-kibana-proxy

## Development

The deployer `run.sh` can run outside a container. In that case it will use
your current kubeconfig context (which must be a cluster admin) to create everything.
You will need the Java JDK, openssl, and of course the openshift/oc client.
Check the script header for optional environment variables that can be supplied.
Define PROJECT to control where everything is created (`default` if not specified);
all others can be left to defaults just for a trial run.

    PUBLIC_MASTER_URL=https://master.example.com:8443 PROJECT=logging ./run.sh

There are some other useful templates for development, including builds
for these components an host-based PVs.

