# Logging Deployer

The deployer pod can enable deploying the full stack of the aggregated
logging solution with just a few prerequisites:

1. A "logging-deployer" Secret
2. A "logging-deployer" ServiceAccount with the secret and create privileges
3. Optionally, a key and certificate for the Kibana server to be deployed.
4. Sufficient volumes defined for ElasticSearch cluster storage.

The deployer generates all the necessary certs/keys/etc for cluster
communication and defines secrets and templates for all of the necessary
API objects to implement aggregated logging. There are a number of
manual steps you must run with cluster-admin privileges in order to
create an OAuth client and modify the privileged SCC so fluentd can run
as a privileged pod on every node.

## Choose a Project

You will likely want to put all logging-related entities in their own project.
For this document we will assume the `logging` project.

    oc new-project logging

You can use the default project if you want, but this implementation
has no need to run in the default project.

If we are forced to deploy fluentd as a static pod, the corresponding
mirror pods will show up in the default project.  They will need to be
configured with the full DNS name of the ElasticSearch service in order
to enter data.

## Create the Deployer Secret

All contents of the secret are optional, but the secret itself must always be
created in order to run the deployer. For an empty secret:

    oc secrets new logging-deployer nothing=/dev/null

The following files may be supplied in the deployer secret:

* `kibana.crt` - A browser-facing certificate for the Kibana server.
* `kibana.key` - A key to be used with the Kibana certificate.
* `kibana-ops.crt` - A browser-facing certificate for the Ops Kibana server.
* `kibana-ops.key` - A key to be used with the Ops Kibana certificate.
* `server-tls.json` - JSON TLS options to override the Kibana server defaults; refer to
  [NodeJS docs](https://nodejs.org/api/tls.html#tls_tls_connect_options_callback) for
  available options and the [default options](conf/server-tls.json) for an example.
* `ca.crt` - A certificate for a CA that will be used to sign all certificates
  generated by the deployer.
* `ca.key` - A matching CA key.

An invocation supplying a properly signed Kibana cert might be:

    oc secrets new logging-deployer \
       kibana.crt=/path/to/cert kibana.key=/path/to/key

## Create the Deployer ServiceAccount

The deployer must run under a service account defined as follows:

    oc create -f - <<API
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: logging-deployer
    secrets:
    - name: logging-deployer
    API

    oc policy add-role-to-user edit \
              system:serviceaccount:logging:logging-deployer

Note: replace `:logging:` with the project name.

## Run the Deployer

You will need to specify the hostname at which Kibana should be exposed to client
browsers, and also the master URL where client browsers will be directed for
authenticating to OpenShift. These and other parameters are availalble:

* `KIBANA_HOSTNAME` (required): External hostname where web clients will reach Kibana
* `PUBLIC_MASTER_URL` (required): External URL for the master, for OAuth purposes
* `IMAGE_PREFIX`: Specify prefix for logging component images; e.g. for "openshift/origin-logging-deployer:v1.1", set prefix "openshift/origin-"
* `IMAGE_VERSION`: Specify version for logging component images; e.g. for "openshift/origin-logging-deployer:v1.1", set version "v1.1"
* `ES_INSTANCE_RAM`: Amount of RAM to reserve per ElasticSearch instance.
* `ES_CLUSTER_SIZE`: How many instances of ElasticSearch to deploy. At least 3 are needed for redundancy, and more can be used for scaling.
* `ENABLE_OPS_CLUSTER`: If "true", configure a second ES cluster and Kibana for ops logs.
* `KIBANA_OPS_HOSTNAME`, `ES_OPS_INSTANCE_RAM`, `ES_OPS_CLUSTER_SIZE`: Parallel parameters for the ops log cluster.

With example parameters:

    oc process logging-deployer-template \
               -v KIBANA_HOSTNAME=kibana.example.com,PUBLIC_MASTER_URL=https://localhost:8443 \
               | oc create -f -

Check the logs of the resulting pod (`oc logs <pod name>`) for some instructions
to follow after deployment. More details are given below.

## Deploy the templates created by the deployer

### Supporting definitions

Create the supporting definitions (you must be cluster admin):

    oc process logging-support-template | oc create -f -

Enable fluentd service account - edit SCC with the following

    oc edit scc/privileged

Add one line as the user at the end: (note, change `:logging:` below to the project of your choice)

    - system:serviceaccount:logging:aggregated-logging-fluentd

Give the account access to read labels from all pods:

    openshift admin policy add-cluster-role-to-user cluster-reader system:serviceaccount:logging:aggregated-logging-fluentd


### ElasticSearch

Scaling a deployment today assumes that all pods can safely share
any volumes specified in the deployment. This is not the case with
ElasticSearch; each pod requires its own storage. Work is under way
to enable specifying multiple volumes to be allocated to instances in
a deployment, but for now multiple deployments are used in order to
scale ElasticSearch. You can view them all with:

    oc get dc --selector logging-infra=elasticsearch

It is possible to scale your cluster up after creation by adding more
deployments; however, when scaling up (or down), you must be aware of
cluster parameters that vary by cluster size and adjust them accordingly
for both new and existing deployments. Elastic [discusses these issues
here](https://www.elastic.co/guide/en/elasticsearch/guide/current/_important_configuration_changes.html)
and the corresponding parameters are coded into the deployments and the
template below.

The deployer defines a template which it uses to create ElasticSearch
deployments. You can adjust and reuse it to add more:

    oc process logging-es-template | oc create -f -

These deployments all have different names but will cluster with each other
via `service/logging-es-cluster`.

Refer to [Elastic's
documentation](https://www.elastic.co/guide/en/elasticsearch/guide/current/hardware.html#_disks)
for considerations involved in choosing storage and network location
as directed below.

#### Storage

The deployer initially creates an ephemeral deployment in which all
of a pod's data will be lost any time it is restarted. For production
use you should specify a persistent storage volume for each deployment
of ElasticSearch. Use the `oc volume` command for adding volumes to
deployments.

For example, to use a local directory on the host (which is actually
recommended by Elastic in order to take advantage of fast local disk):

    oc volume dc/logging-es-rca2m9u8 \
              --add --overwrite --name=elasticsearch-storage \
              --type=hostPath --path=/path/to/storage

Note: In order to allow the pods to mount host volumes, you would usually
need to add the `aggregated-logging-elasticsearch` service account to
the privileged SCC as shown for Fluentd above.

See `oc volume -h` for further options. E.g. if you have an NFS volume
you would like to use, you can set it with:

    oc volume dc/logging-es-rca2m9u8 \
              --add --overwrite --name=elasticsearch-storage \
              --source='{"nfs": {"server": "nfs.server.example.com", "path": "/exported/path"}}'

#### Node selector

ElasticSearch can be very resource-heavy, particularly in RAM, depending
on the volume of logs your cluster generates. Per Elastic's guidance,
all members of the cluster should have low latency network connections
to each other.  You will likely want to direct the instances to dedicated
nodes, or a dedicated region in your cluster. You can do this by supplying
a node selector in each deployment.

There is no helpful command for adding a node selector. You will need to
hand-edit each DeploymentConfig and add the `nodeSelector` element to specify
the label corresponding to your desired nodes, e.g.:

    apiVersion: v1
    kind: DeploymentConfig
    spec:
      nodeSelector:
        nodelabel: logging-es-node-1

Recall that the default scheduler algorithm will spread pods to different
nodes (in the same region, if regions are defined). However this can
have unexpected consequences in several scenarios and you will most
likely want to label and specify designated nodes for ElasticSearch.

#### Settings

There are some administrative settings that can be supplied (ref. [Elastic documentation](https://www.elastic.co/guide/en/elasticsearch/guide/current/_important_configuration_changes.html)).

* `minimum_master_nodes` - the quorum required to elect a new master. Should be more than half the intended cluster size.
* `recover_after_nodes` - when restarting the cluster, require this many nodes to be present before starting recovery.
* `expected_nodes` and `recover_after_time` - when restarting the cluster, wait for number of nodes to be present or time to expire before starting recovery.

These are, respectively, the `NODE_QUORUM`, `RECOVER_AFTER_NODES`,
`RECOVER_EXPECTED_NODES`, and `RECOVER_AFTER_TIME` parameters in the
deployments and the ES template. The deployer also enables specifying
these parameters (with the `ES_` prefix), however usually its defaults
should be sufficient.

### Fluentd

Once you have ElasticSearch running as desired, deploy fluentd on every
node to feed logs into it.

    oc process logging-fluentd-template | oc create -f -

You may scale the resulting deployment normally to the number of nodes:

    oc scale dc/logging-fluentd --replicas=3
    oc scale rc/logging-fluentd-1 --replicas=3

This implementation is not intended for production as it does not
dynamically grow and shrink with the number of nodes, and uses a fake
port reservation to prevent multiple replicas on one node. One of two
methods is intended for production:

1. Use the experimental DaemonController (once available) to schedule
   the pod with a NodeSet including every node.
2. Extract the pod definition from the template output, copy it to every
   node, and ensure every node uses it as a static pod.

### Kibana

Finally, deploy the user interface, Kibana.

    oc process logging-kibana-template | oc create -f -

You may scale the resulting deployment normally for redundancy:

    oc scale dc/logging-kibana --replicas=2
    oc scale rc/logging-kibana-1 --replicas=2

Once this is running, you should be able to visit the `KIBANA_HOSTNAME`
specified above to visit the UI (assuming DNS points correctly for
this domain).

### Ops cluster

If you set `ENABLE_OPS_CLUSTER` to `true` for the deployer, fluentd
expects to split logs between the main ElasticSearch cluster and another
cluster reserved for operations logs (node logs and `default` project).
Thus a separate ElasticSearch cluster and a separate Kibana are deployed
to index and access operations logs. These deployments are set apart with
the `-ops` included in their names. The same considerations apply as
for the main cluster.

## Cleanup and removal

After deployment, the deployer account and secret can be removed.

    oc delete sa/logging-deployer secret/logging-deployer

If you wish to remove everything generated or instantiated without having
to destroy the project:

    oc delete all --selector logging-infra=kibana
    oc delete all --selector logging-infra=fluentd
    oc delete all --selector logging-infra=elasticsearch
    oc delete all,sa,oauthclient --selector logging-infra=support
    oc delete secret logging-fluentd logging-elasticsearch logging-es-proxy logging-kibana logging-kibana-proxy logging-kibana-ops-proxy
